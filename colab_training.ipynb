{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is basically the same as model_training.py except written in a jupyter notebook so it can work with google colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gdown #<-- lets you get drive files into colab using their file ids ig\n",
    "!pip install tensorflow-gpu #<-- leverages tensor flows GPU library which make things faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown --id #insert id here# --output ##insert file name here\n",
    "!gdown --id #insert id here# --output ##insert file name here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change file names in the following two\n",
    "cook_df = pd.read_csv('./samples/cook.csv')\n",
    "flick_df = pd.read_csv('./samples/flickup.csv')\n",
    "\n",
    "#getting rid of last 5 elements from cook_df\n",
    "flick_df = flick_df[0:len(flick_df)-10]\n",
    "\n",
    "#since one second is about 118 rows, im getting rid of the extra rows that would make it evenly divisible\n",
    "cook_df = cook_df[0:len(cook_df)-len(cook_df)%118]\n",
    "flick_df = flick_df[0:len(flick_df)-len(flick_df)%118]\n",
    "\n",
    "print(cook_df.info())\n",
    "print(flick_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cook_df['Time'] = cook_df['Time'].astype(float)\n",
    "flick_df['Time'] = flick_df['Time'].astype(float)\n",
    "\n",
    "\n",
    "cook_df = cook_df.drop(columns = ['Gx', 'Gy', 'Gz'])\n",
    "flick_df = flick_df.drop(columns = ['Gx', 'Gy', 'Gz'])\n",
    "\n",
    "cook_df['Class'] = 'cook'\n",
    "flick_df['Class'] = 'flick'\n",
    "\n",
    "cook_df.info()\n",
    "flick_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cook_df = cook_df[0:int(len(cook_df)*.9)]\n",
    "test_cook_df = cook_df[int(len(cook_df)*.9):]\n",
    "\n",
    "train_flick_df = flick_df[0:int(len(flick_df)*.9)]\n",
    "test_flick_df = flick_df[int(len(flick_df)*.9):]\n",
    "\n",
    "window = 49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatData(X,Y, window):\n",
    "    Xarr = []\n",
    "    Yarr = []\n",
    "\n",
    "    for i in range(0, len(X) - window, int(window/2)):\n",
    "        Xarr.append(X.iloc[i:i+window].values)  \n",
    "        Yarr.append(Y.iloc[0])\n",
    "\n",
    "    return np.array(Xarr), np.array(Yarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test data \n",
    "X_train1, Y_train1 = formatData(train_cook_df[['Ax', 'Ay', 'Az']], train_cook_df[['Class']], window)\n",
    "X_train2, Y_train2 = formatData(train_flick_df[['Ax', 'Ay', 'Az']], train_flick_df[['Class']], window)\n",
    "\n",
    "#train data\n",
    "X_test1, Y_test1 = formatData(test_cook_df[['Ax', 'Ay', 'Az']], test_cook_df[['Class']], window)\n",
    "X_test2, Y_test2 = formatData(test_flick_df[['Ax', 'Ay', 'Az']], test_flick_df[['Class']], window)\n",
    "\n",
    "\n",
    "#manually encoding because i didnt do it earlier and it would be a pain to go back. \n",
    "#will change when i add more classes\n",
    "for i in range(len(Y_train1)):\n",
    "    Y_train1[i] = 0\n",
    "    Y_train2[i] = 1\n",
    "\n",
    "for i in range(len(Y_test1)):\n",
    "    Y_test1[i] = 0\n",
    "    Y_test2[i] = 1\n",
    "\n",
    "X_train_final = np.concatenate((X_train1, X_train2))\n",
    "Y_train_final = np.concatenate((Y_train1, Y_train2))\n",
    "\n",
    "X_test_final = np.concatenate((X_test1, X_test2))\n",
    "Y_test_final = np.concatenate((Y_test1, Y_test2))\n",
    "\n",
    "\n",
    "print(np.shape(X_train_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "#add bidirection lstm layer\n",
    "model.add(\n",
    "    keras.layers.Bidirectional(\n",
    "        keras.layers.LSTM(\n",
    "            units=128,\n",
    "            input_shape = [X_train_final.shape[1], X_train_final.shape[2]]\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "#adding a dropout layer (prevents overfitting - look it up)\n",
    "model.add(keras.layer.Dropout(rate=0.5))\n",
    "\n",
    "#dense layer is the layer of nodes\n",
    "model.add(keras.layers.Dense(units=128, activation='relu'))\n",
    "\n",
    "#this layer will return the output prediction. Softmax puts \"confidence\" between 0 and 1\n",
    "model.add(keras.layers.Dense(Y_train_final.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentrropy', optimizer='adam', metrics=['acc'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch size will be played around with bc my data is small :/\n",
    "trained_model = model.fit(\n",
    "    X_train_final, Y_train_final,\n",
    "    epochs =20,\n",
    "    batch_size=16,\n",
    "    validation_split= 0.1,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
